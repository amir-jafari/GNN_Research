#### Week of 1st Oct:
- Understanding fundamentals of GNN.
- Understanding GAT and how GNN general formula is extended in case of attention mechanism.
- Refer the doc for information on the above two points (https://docs.google.com/document/d/1P1GNMqsOqBuEuW1AilSCwIrlLWFuNx7P2atqdtZO6GM/edit)

  #### Action items:
  - Showing learning process with code implementation.
    - Node classification notebook
    - What are supervised classification we can do using GNN?
        - Explain the data using EDA.
        - Explain the learning process for each step.
  - Understand GCN.
  - Copying the content from GNN_Report doc to Overleaf paper.

#### Week of 8th Oct:
- Understanding GCN
- Node classification
- Showing learning process with code implementation.

  #### Action Items:
  - Checkout a branch from main and work on the new branch.
  - To be discussed

#### Week  of 15th Oct:
- Understanding transition from GCN to GAT
- Re-visit Node classification code

  #### Action Items:
  - Meet up with Tyler (10/18/2024)

#### Week of 25th Oct:
- Walkthrough of Iris dataset for Node Classification.

#### Action Items:

- [ ] Explore DataLoader: Experiment with the batch_size parameter in DataLoader to understand how it affects edge_index.
- [ ] Provide a clear explanation of what a homogeneous graph and heterographs are and highlight their difference.
- [ ] Use PyTorch Geometric: Perform all calculations, including distance calculations, using PyTorch Geometric.
- [ ] Test multiple values for k parameter to find the best ones.
- [ ] Check Shapes: After each GCN layer, check the shape of the output to understand how it changes.
- [ ] Go through training phase again and state the reason of using a particular loss function and optimizer. Infact, debug training phase thoroughly.